{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MG_Vidin_2019_RestaurantSentimentAnalysis.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kabranov/vidin/blob/master/MG_Vidin_2019_RestaurantSentimentAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Pi5-n5uF4rP"
      },
      "source": [
        "\n",
        "reference\n",
        "https://www.kaggle.com/apekshakom/sentiment-analysis-of-restaurant-reviews\n",
        "\n",
        "https://www.geeksforgeeks.org/python-nlp-analysis-of-restaurant-reviews/\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WduUaP8vGBy4"
      },
      "source": [
        "\n",
        "#Анализ на сентименти на ревюта за ресторанти\n",
        "\n",
        "Целта на този анализ е да се създаде предиктивен модел да се предскаже дали сентимента на коментар на ресторант е позитивен или негативен. За обучение на модела ще използваме логистична регресия. \n",
        "\n",
        "Dataset: https://www.kaggle.com/hj5992/restaurantreviews\n",
        " \n",
        " \n",
        "Базата от данни е от Kaggle datasets - 1000 ревюта на ресторанти.\n",
        "\n",
        "необходимо да направим следните стъпки:\n",
        "- да се импортира базата от данни \n",
        "- да се извърши предварителна обработка\n",
        "- векторизация\n",
        "- Обучение и класификация\n",
        "- Анализ и заключние\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCo-oFVKGv4A"
      },
      "source": [
        "# да се импортира базата от данни\n",
        "\n",
        "> Indented block\n",
        "\n",
        "\n",
        "Импорт на базата данни, използвайки pandas библиотека.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-puHh3sG73_"
      },
      "source": [
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2VnCFj6G-z9",
        "outputId": "a868924b-9953-46e1-b4b1-11f946a0ef7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "# Importing the datas\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# That will not be needed if it executed on a local drive.\n",
        "\n",
        "import os\n",
        "cwd = os.getcwd()\n",
        "print(cwd)\n",
        "print(os.listdir() )\n",
        "dataset = pd.read_csv('/content/drive/My Drive/Restaurant_Reviews.tsv', delimiter = '\\t', quoting = 3)\n",
        "\n",
        "!ls -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "/content\n",
            "['.config', 'drive', 'sample_data']\n",
            "total 8\n",
            "drwx------ 4 root root 4096 Mar 12 05:56 drive\n",
            "drwxr-xr-x 1 root root 4096 Mar  3 18:11 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5E-GBLPKM-Yc",
        "outputId": "a421e761-b2c1-48e4-e3d1-57bf2b45f0c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 996
        }
      },
      "source": [
        "print(\"size=%d\",dataset.size)\n",
        "dataset.head(30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size=%d 2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Liked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Now I am getting angry and I want my damn pho.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Honeslty it didn't taste THAT fresh.)</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The potatoes were like rubber and you could te...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>The fries were great too.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>A great touch.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Service was very prompt.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Would not go back.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>The cashier had no care what so ever on what I...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>I tried the Cape Cod ravoli, chicken, with cra...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>I was disgusted because I was pretty sure that...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>I was shocked because no signs indicate cash o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Highly recommended.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Waitress was a little slow in service.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>This place is not worth your time, let alone V...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>did not like at all.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>The Burrittos Blah!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>The food, amazing.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Service is also cute.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>I could care less... The interior is just beau...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>So they performed.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>That's right....the red velvet cake.....ohhh t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>- They never brought a salad we asked for.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>This hole in the wall has great Mexican street...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Took an hour to get our food only 4 tables in ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>The worst was the salmon sashimi.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Review  Liked\n",
              "0                            Wow... Loved this place.      1\n",
              "1                                  Crust is not good.      0\n",
              "2           Not tasty and the texture was just nasty.      0\n",
              "3   Stopped by during the late May bank holiday of...      1\n",
              "4   The selection on the menu was great and so wer...      1\n",
              "5      Now I am getting angry and I want my damn pho.      0\n",
              "6               Honeslty it didn't taste THAT fresh.)      0\n",
              "7   The potatoes were like rubber and you could te...      0\n",
              "8                           The fries were great too.      1\n",
              "9                                      A great touch.      1\n",
              "10                           Service was very prompt.      1\n",
              "11                                 Would not go back.      0\n",
              "12  The cashier had no care what so ever on what I...      0\n",
              "13  I tried the Cape Cod ravoli, chicken, with cra...      1\n",
              "14  I was disgusted because I was pretty sure that...      0\n",
              "15  I was shocked because no signs indicate cash o...      0\n",
              "16                                Highly recommended.      1\n",
              "17             Waitress was a little slow in service.      0\n",
              "18  This place is not worth your time, let alone V...      0\n",
              "19                               did not like at all.      0\n",
              "20                                The Burrittos Blah!      0\n",
              "21                                 The food, amazing.      1\n",
              "22                              Service is also cute.      1\n",
              "23  I could care less... The interior is just beau...      1\n",
              "24                                 So they performed.      1\n",
              "25  That's right....the red velvet cake.....ohhh t...      1\n",
              "26         - They never brought a salad we asked for.      0\n",
              "27  This hole in the wall has great Mexican street...      1\n",
              "28  Took an hour to get our food only 4 tables in ...      0\n",
              "29                  The worst was the salmon sashimi.      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNmxeRaEPjEE"
      },
      "source": [
        "#Предварителна обработка\n",
        "\n",
        "Всяко ревю се подлага на предварителна обработка, където:\n",
        "\n",
        "- премахват се stopwords, numeric и speacial charecters.\n",
        "- извирвършва се stemming.\n",
        "\n",
        "![alt text](https://media.geeksforgeeks.org/wp-content/uploads/stemming.png)\n",
        "\n",
        "използва се само корена на думата."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWlZi4oUNGhK",
        "outputId": "774c83d0-0c28-40e5-f4c4-c8495bb1fbc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# library to clean data \n",
        "import re\n",
        "# Natural Language Tool Kit \n",
        "import nltk\n",
        "# for Stemming propose \n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "# Initialize empty array \n",
        "# to append clean text  \n",
        "corpus = []\n",
        "nltk.download('stopwords')\n",
        "# 1000 (reviews) rows to clean \n",
        "for i in range(0, 1000):\n",
        "    # column : \"Review\", row ith \n",
        "    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n",
        "    # convert all cases to lower cases \n",
        "    review = review.lower()\n",
        "    # split to array(default delimiter is \" \")\n",
        "    review = review.split()\n",
        "    # creating PorterStemmer object to \n",
        "    # take main stem of each word \n",
        "    ps = PorterStemmer()\n",
        "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
        "    # rejoin all string array elements \n",
        "    # to create back into a string \n",
        "    review = ' '.join(review)\n",
        "          \n",
        "    # append each string to create \n",
        "    # array of clean text\n",
        "    corpus.append(review)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtNKL6DJKhGF",
        "outputId": "19e923ba-bf13-4d5b-f6ab-e3ed089b01f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "print( dataset)\n",
        "print(\"---\")\n",
        "for i in range(0,10):\n",
        "  print( dataset['Review'][i],\"--->\", dataset['Liked'][i])\n",
        "  print(\"==> stemmed : \" , corpus[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                Review  Liked\n",
            "0                             Wow... Loved this place.      1\n",
            "1                                   Crust is not good.      0\n",
            "2            Not tasty and the texture was just nasty.      0\n",
            "3    Stopped by during the late May bank holiday of...      1\n",
            "4    The selection on the menu was great and so wer...      1\n",
            "..                                                 ...    ...\n",
            "995  I think food should have flavor and texture an...      0\n",
            "996                           Appetite instantly gone.      0\n",
            "997  Overall I was not impressed and would not go b...      0\n",
            "998  The whole experience was underwhelming, and I ...      0\n",
            "999  Then, as if I hadn't wasted enough of my life ...      0\n",
            "\n",
            "[1000 rows x 2 columns]\n",
            "---\n",
            "Wow... Loved this place. ---> 1\n",
            "==> stemmed :  wow love place\n",
            "Crust is not good. ---> 0\n",
            "==> stemmed :  crust good\n",
            "Not tasty and the texture was just nasty. ---> 0\n",
            "==> stemmed :  tasti textur nasti\n",
            "Stopped by during the late May bank holiday off Rick Steve recommendation and loved it. ---> 1\n",
            "==> stemmed :  stop late may bank holiday rick steve recommend love\n",
            "The selection on the menu was great and so were the prices. ---> 1\n",
            "==> stemmed :  select menu great price\n",
            "Now I am getting angry and I want my damn pho. ---> 0\n",
            "==> stemmed :  get angri want damn pho\n",
            "Honeslty it didn't taste THAT fresh.) ---> 0\n",
            "==> stemmed :  honeslti tast fresh\n",
            "The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer. ---> 0\n",
            "==> stemmed :  potato like rubber could tell made ahead time kept warmer\n",
            "The fries were great too. ---> 1\n",
            "==> stemmed :  fri great\n",
            "A great touch. ---> 1\n",
            "==> stemmed :  great touch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qk9V19n-Q5ut"
      },
      "source": [
        "#Векторизация\n",
        "\n",
        "\n",
        "От изчистения набор от данни се извличат думите и се преобразуват във векторизиран формат. Техниките за векторизация се използват за преобразуване на текстови данни в цифров формат. С помощта на векторизация се създава матрица, където всяка колона представлява функция и всеки ред представлява индивидуално ревю.\n",
        "\n",
        "\n",
        "Input : \n",
        "* \"dam good steak\", \n",
        "* \"good food good servic\"\n",
        "\n",
        "Output :\n",
        "\n",
        "![alt text](https://media.geeksforgeeks.org/wp-content/uploads/eg.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U11AwkrDPrTA"
      },
      "source": [
        "# Creating the Bag of Words model using CountVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# To extract max 1500 feature. \n",
        "# \"max_features\" is attribute to \n",
        "# experiment with to get better results \n",
        "\n",
        "cv = CountVectorizer(max_features = 1500)\n",
        "\n",
        "# X contains corpus (dependent variable) \n",
        "X = cv.fit_transform(corpus).toarray()\n",
        "\n",
        "# y contains answers if review \n",
        "# is positive or negative \n",
        "y = dataset.iloc[:, 1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2k4_NtSRG0P"
      },
      "source": [
        "#dataset.iloc[:, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FJBEZfsR5TN"
      },
      "source": [
        "#dataset.iloc[:, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZNAWXwqR7wx",
        "outputId": "454a13b9-22b7-4bdb-9d91-b2067343aae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print(X)\n",
        "print(len(X[0]))\n",
        "print(X[0][10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "1500\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4_8X2lTXQ2r"
      },
      "source": [
        "# Обучение и класификация\n",
        "о-нататък данните се разделят на набор за обучение и тестване. Тези данни се използват като вход към алгоритъма за класификация.\n",
        "За предиктивен модел се изполсва логистична класификация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr7p2DU2XYY6"
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk-R7ICwXthP",
        "outputId": "18f90cb0-f9f0-4e3f-e5df-9f7b16b3e153",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Logistic Regression\n",
        "\n",
        "# Fitting Logistic Regression to the Training set\n",
        "from sklearn import linear_model\n",
        "classifier = linear_model.LogisticRegression(C=1.5)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "\n",
        "# Accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "score1 = accuracy_score(y_test,y_pred)\n",
        "print(\"\\n\")\n",
        "print(\"Accuracy is \",round(score1*100,2),\"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Accuracy is  76.67 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7Z3rrz4ZQMi",
        "outputId": "863176a8-e86b-4cea-d4fb-c4cd90e63e59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(cv.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['absolut', 'absolutley', 'accid', 'accommod', 'accomod', 'accordingli', 'account', 'ach', 'acknowledg', 'across', 'actual', 'ad', 'afford', 'afternoon', 'ago', 'ahead', 'airlin', 'airport', 'ala', 'albondiga', 'allergi', 'almond', 'almost', 'alon', 'also', 'although', 'alway', 'amaz', 'ambianc', 'ambienc', 'amount', 'ampl', 'andddd', 'angri', 'annoy', 'anoth', 'anticip', 'anymor', 'anyon', 'anyth', 'anytim', 'anyway', 'apart', 'apolog', 'app', 'appal', 'appar', 'appeal', 'appet', 'appetit', 'appl', 'approv', 'area', 'arepa', 'aria', 'around', 'array', 'arriv', 'articl', 'ask', 'assur', 'ate', 'atmospher', 'atroci', 'attach', 'attack', 'attent', 'attitud', 'auju', 'authent', 'averag', 'avocado', 'avoid', 'aw', 'away', 'awesom', 'awkward', 'awkwardli', 'ayc', 'az', 'baba', 'babi', 'bachi', 'back', 'bacon', 'bad', 'bagel', 'bakeri', 'baklava', 'ball', 'bamboo', 'banana', 'bank', 'bar', 'bare', 'bargain', 'bartend', 'base', 'basebal', 'basic', 'batch', 'bathroom', 'batter', 'bay', 'bbq', 'bean', 'beat', 'beateou', 'beauti', 'becom', 'beef', 'beer', 'begin', 'behind', 'believ', 'bellagio', 'belli', 'besid', 'best', 'better', 'beyond', 'big', 'bigger', 'biggest', 'bill', 'bing', 'bird', 'biscuit', 'bisqu', 'bit', 'bite', 'black', 'bland', 'bloddi', 'bloodi', 'blow', 'blown', 'blue', 'boba', 'bone', 'book', 'boot', 'bore', 'bother', 'bottom', 'bouchon', 'bought', 'bowl', 'box', 'boy', 'boyfriend', 'bread', 'break', 'breakfast', 'breez', 'brick', 'bring', 'brisket', 'brother', 'brought', 'brownish', 'brunch', 'bruschetta', 'brushfir', 'bu', 'buck', 'buffet', 'bug', 'build', 'buldogi', 'bunch', 'burger', 'burn', 'burritto', 'busi', 'bussel', 'butter', 'buy', 'bye', 'caballero', 'caesar', 'caf', 'cafe', 'cake', 'calamari', 'call', 'calligraphi', 'came', 'camelback', 'cannoli', 'cannot', 'cant', 'cape', 'caper', 'car', 'carb', 'care', 'carli', 'carpaccio', 'cart', 'cartel', 'case', 'cash', 'cashew', 'cashier', 'casino', 'caterpillar', 'chain', 'chang', 'char', 'charcoal', 'charg', 'charm', 'cheap', 'cheat', 'check', 'cheek', 'chees', 'cheeseburg', 'cheesecurd', 'chef', 'chewi', 'chicken', 'chines', 'chip', 'chipolt', 'chipotl', 'chocol', 'choos', 'choux', 'chow', 'christma', 'cibo', 'circumst', 'claim', 'class', 'classi', 'classic', 'clean', 'climb', 'close', 'club', 'clue', 'cocktail', 'coconut', 'cod', 'coffe', 'cold', 'colder', 'colleg', 'color', 'combin', 'combo', 'come', 'comfort', 'common', 'compani', 'companion', 'complain', 'complaint', 'complet', 'compliment', 'con', 'concept', 'concern', 'conclus', 'condiment', 'connisseur', 'connoisseur', 'consid', 'consist', 'construct', 'contain', 'continu', 'conveni', 'cook', 'cool', 'corn', 'corpor', 'correct', 'cost', 'costco', 'cotta', 'could', 'count', 'coupl', 'coupon', 'cours', 'court', 'courteou', 'cover', 'cow', 'cozi', 'cr', 'crab', 'cram', 'cranberri', 'crave', 'crawfish', 'crazi', 'cream', 'creami', 'crema', 'crepe', 'crisp', 'crispi', 'crostini', 'crouton', 'crowd', 'crumbi', 'crust', 'crusti', 'crystal', 'cuisin', 'curri', 'custom', 'cut', 'cute', 'daili', 'damn', 'dark', 'date', 'daughter', 'day', 'dead', 'deal', 'decent', 'decid', 'decis', 'decor', 'dedic', 'deep', 'deepli', 'def', 'defin', 'definit', 'degre', 'del', 'delic', 'delici', 'delicioso', 'delight', 'delish', 'deliv', 'deliveri', 'denni', 'describ', 'descript', 'deserv', 'desir', 'despic', 'despit', 'dessert', 'deuchebaggeri', 'devin', 'die', 'differ', 'dime', 'dine', 'dinner', 'dip', 'dirt', 'dirti', 'disagre', 'disappoint', 'disapppoint', 'disast', 'disbelief', 'discount', 'disgrac', 'disgust', 'dish', 'dispens', 'disrespect', 'divers', 'do', 'dog', 'dollar', 'done', 'dont', 'donut', 'door', 'doubl', 'doubt', 'douchey', 'dough', 'doughi', 'downright', 'downsid', 'downtown', 'drag', 'drastic', 'draw', 'dream', 'drench', 'dress', 'dri', 'driest', 'drink', 'drip', 'drive', 'drop', 'drunk', 'duck', 'dude', 'due', 'duo', 'dust', 'dylan', 'easili', 'eat', 'eaten', 'eclect', 'ed', 'edibl', 'edinburgh', 'edit', 'eel', 'eew', 'effici', 'effort', 'egg', 'eggplant', 'either', 'elegantli', 'elk', 'els', 'elsewher', 'email', 'employe', 'empti', 'end', 'english', 'enjoy', 'enough', 'ensu', 'enthusiast', 'entir', 'entre', 'equal', 'especi', 'establish', 'etc', 'ethic', 'eve', 'even', 'event', 'ever', 'everi', 'everyon', 'everyth', 'everywher', 'exactli', 'excalibur', 'exceed', 'excel', 'except', 'excus', 'expand', 'expect', 'expens', 'experi', 'experienc', 'expert', 'exquisit', 'extens', 'extra', 'extrem', 'eye', 'fact', 'fail', 'fairli', 'famili', 'familiar', 'fan', 'fantast', 'far', 'fare', 'fast', 'favor', 'favorit', 'feel', 'fell', 'fella', 'fellow', 'felt', 'fianc', 'figur', 'filet', 'fill', 'fillet', 'final', 'find', 'fine', 'finish', 'firebal', 'firehous', 'first', 'fish', 'five', 'flair', 'flat', 'flavor', 'flavorless', 'flavour', 'fli', 'flirt', 'flop', 'flower', 'fluffi', 'fo', 'focus', 'folk', 'fondu', 'food', 'foot', 'forev', 'forget', 'forth', 'forti', 'forward', 'found', 'four', 'francisco', 'freak', 'free', 'freez', 'frenchman', 'fresh', 'fri', 'friday', 'friend', 'friendli', 'front', 'frozen', 'fruit', 'frustrat', 'fs', 'fuck', 'full', 'fun', 'funni', 'furthermor', 'fuzzi', 'ga', 'ganoush', 'garden', 'garlic', 'gave', 'gc', 'gem', 'gener', 'genuin', 'get', 'giant', 'girlfriend', 'give', 'given', 'glad', 'glanc', 'glass', 'glove', 'gluten', 'go', 'goat', 'godfath', 'gold', 'golden', 'gone', 'good', 'googl', 'gooodd', 'gordon', 'got', 'gotten', 'gourmet', 'grab', 'grain', 'grandmoth', 'gratitud', 'gratuiti', 'greas', 'greasi', 'great', 'greatest', 'greedi', 'greek', 'green', 'greet', 'grill', 'gringo', 'gristl', 'groceri', 'gross', 'ground', 'group', 'grow', 'guacamol', 'guess', 'guest', 'guy', 'gyro', 'ha', 'hair', 'half', 'halibut', 'hamburg', 'han', 'hand', 'handl', 'handmad', 'hanker', 'happen', 'happi', 'happier', 'hard', 'hardest', 'hardli', 'hate', 'haunt', 'hawaiian', 'head', 'healthi', 'heard', 'heart', 'heat', 'heimer', 'held', 'hell', 'hella', 'hello', 'help', 'herea', 'hi', 'high', 'highli', 'highlight', 'hilari', 'hip', 'hiro', 'hit', 'hole', 'holiday', 'home', 'homemad', 'honeslti', 'honest', 'honestli', 'honor', 'hook', 'hope', 'horribl', 'hospit', 'host', 'hostess', 'hot', 'hottest', 'hour', 'hous', 'howev', 'huevo', 'huge', 'human', 'humili', 'hummu', 'hunan', 'hungri', 'hurri', 'husband', 'hut', 'ian', 'ice', 'idea', 'ignor', 'im', 'imagin', 'immedi', 'impecc', 'impress', 'inch', 'includ', 'inconsider', 'incred', 'indian', 'indic', 'indoor', 'industri', 'inexpens', 'inflat', 'inform', 'ingredi', 'insan', 'insid', 'inspir', 'instantli', 'instead', 'insult', 'interest', 'interior', 'invit', 'ironman', 'italian', 'item', 'jalapeno', 'jamaican', 'japanes', 'jeff', 'jenni', 'jerk', 'jewel', 'job', 'joey', 'join', 'joint', 'joke', 'joy', 'judg', 'juic', 'juri', 'kabuki', 'kept', 'key', 'khao', 'kid', 'kiddo', 'killer', 'kind', 'kitchen', 'know', 'known', 'la', 'lack', 'ladi', 'larg', 'larger', 'last', 'lastli', 'late', 'later', 'latt', 'law', 'lawyer', 'lb', 'least', 'leather', 'leav', 'left', 'leftov', 'leg', 'legit', 'lemon', 'less', 'let', 'letdown', 'lettuc', 'level', 'life', 'light', 'lighter', 'lightli', 'like', 'lil', 'limit', 'line', 'list', 'liter', 'littl', 'live', 'lobster', 'locat', 'long', 'longer', 'look', 'lordi', 'lost', 'lot', 'loudli', 'love', 'lover', 'low', 'lox', 'loyal', 'luck', 'luke', 'lukewarm', 'lunch', 'mac', 'macaron', 'made', 'madhous', 'madison', 'magazin', 'magic', 'main', 'maintain', 'make', 'mall', 'man', 'manag', 'mandalay', 'mango', 'mani', 'margarita', 'mari', 'maria', 'market', 'marrow', 'martini', 'massiv', 'may', 'mayb', 'mayo', 'meal', 'mean', 'meat', 'meatbal', 'meatloaf', 'mediocr', 'mediterranean', 'medium', 'meet', 'meh', 'mein', 'mellow', 'melt', 'memori', 'mention', 'menu', 'mesquit', 'mess', 'metro', 'mexican', 'mgm', 'mid', 'middl', 'might', 'mile', 'militari', 'milk', 'milkshak', 'min', 'mind', 'minut', 'mirag', 'miss', 'mistak', 'mix', 'mmmm', 'modern', 'moist', 'mojito', 'mom', 'money', 'monster', 'month', 'mood', 'mortifi', 'mostli', 'mouth', 'movi', 'moz', 'mozzarella', 'much', 'muffin', 'multi', 'multipl', 'mushroom', 'music', 'must', 'nacho', 'nasti', 'nay', 'nearli', 'neat', 'need', 'needless', 'neglig', 'neighborhood', 'neither', 'never', 'new', 'next', 'nice', 'nicest', 'night', 'nigiri', 'ninja', 'nobu', 'noca', 'non', 'none', 'noodl', 'north', 'note', 'noth', 'nude', 'number', 'nut', 'nutshel', 'nyc', 'obvious', 'offer', 'oh', 'ok', 'old', 'omg', 'one', 'opportun', 'option', 'order', 'other', 'outsid', 'outstand', 'oven', 'overal', 'overcook', 'overpr', 'overwhelm', 'owner', 'pace', 'pack', 'paid', 'pancak', 'paper', 'par', 'part', 'parti', 'pass', 'pasta', 'patio', 'patti', 'pay', 'pe', 'pea', 'peach', 'peanut', 'pear', 'pecan', 'penn', 'peopl', 'pepper', 'perfect', 'perfectli', 'perform', 'perhap', 'perpar', 'person', 'petrifi', 'petti', 'phenomen', 'philadelphia', 'pho', 'phoenix', 'piano', 'pictur', 'piec', 'pile', 'pine', 'pineappl', 'pink', 'pissd', 'pita', 'pizza', 'place', 'plain', 'plantain', 'plastic', 'plate', 'plater', 'platter', 'play', 'pleas', 'pleasant', 'pleasur', 'plethora', 'plu', 'pneumat', 'point', 'poison', 'polit', 'poop', 'poor', 'poorli', 'pop', 'pork', 'portion', 'posit', 'possibl', 'postino', 'potato', 'pour', 'powder', 'power', 'prefer', 'prepar', 'present', 'pretti', 'price', 'pricey', 'prime', 'privileg', 'pro', 'probabl', 'problem', 'proclaim', 'profession', 'profiterol', 'profound', 'promis', 'prompt', 'promptli', 'properli', 'proven', 'provid', 'pub', 'public', 'publicli', 'puck', 'pull', 'pumpkin', 'pur', 'pure', 'put', 'quaint', 'qualifi', 'qualiti', 'quantiti', 'quick', 'quickli', 'quit', 'ramsey', 'ranch', 'ranchero', 'rapidli', 'rare', 'raspberri', 'rate', 'rather', 'ratio', 'rave', 'ravoli', 'read', 'reader', 'real', 'realiz', 'realli', 'reason', 'recal', 'receiv', 'recent', 'recommend', 'red', 'redeem', 'reduct', 'refil', 'refrain', 'refresh', 'refri', 'refus', 'regist', 'regular', 'regularli', 'reheat', 'relationship', 'relax', 'relleno', 'reloc', 'rememb', 'remind', 'replenish', 'request', 'reserv', 'rest', 'restaraunt', 'restaur', 'return', 'review', 'revisit', 'rge', 'ri', 'rib', 'ribey', 'rice', 'rich', 'rick', 'ridicul', 'right', 'ring', 'rins', 'rip', 'risotto', 'roast', 'rock', 'roll', 'room', 'rotat', 'round', 'rowdi', 'rubber', 'rude', 'run', 'rush', 'ryan', 'sad', 'sadli', 'saffron', 'saganaki', 'said', 'sal', 'salad', 'salmon', 'salsa', 'salt', 'salti', 'sampl', 'san', 'sandwich', 'sangria', 'sashimi', 'sat', 'satifi', 'satisfi', 'sauc', 'saus', 'save', 'say', 'scallop', 'scene', 'scottsdal', 'scream', 'screw', 'seafood', 'seal', 'season', 'seat', 'second', 'section', 'see', 'seem', 'seen', 'select', 'self', 'send', 'sens', 'sergeant', 'serious', 'serivc', 'serv', 'server', 'servic', 'set', 'sever', 'sewer', 'sexi', 'shall', 'sharpli', 'shawarrrrrrma', 'shirt', 'shock', 'shoe', 'shoot', 'shop', 'short', 'shot', 'show', 'shower', 'shrimp', 'sick', 'side', 'sign', 'silent', 'similar', 'similarli', 'simpl', 'simpli', 'sinc', 'singl', 'sit', 'six', 'skimp', 'slaw', 'slice', 'slow', 'small', 'smaller', 'smashburg', 'smear', 'smell', 'smoke', 'smooth', 'smoothi', 'soggi', 'soi', 'solid', 'solidifi', 'somehow', 'someon', 'someth', 'somethat', 'somewhat', 'son', 'song', 'soon', 'soooo', 'sooooo', 'soooooo', 'sore', 'sorri', 'sound', 'soundtrack', 'soup', 'sour', 'southwest', 'space', 'spaghetti', 'special', 'speedi', 'spend', 'spice', 'spici', 'spicier', 'spinach', 'sport', 'spot', 'spotti', 'spring', 'sprout', 'staff', 'stale', 'standard', 'star', 'start', 'starv', 'station', 'stay', 'steak', 'steakhous', 'steiner', 'step', 'steve', 'stick', 'still', 'stink', 'stir', 'stomach', 'stood', 'stop', 'store', 'strang', 'stranger', 'strawberri', 'street', 'stretch', 'strike', 'string', 'strip', 'struck', 'struggl', 'stuf', 'stuff', 'stupid', 'style', 'styrofoam', 'sub', 'subpar', 'subway', 'succul', 'suck', 'sucker', 'suffer', 'sugar', 'sugari', 'suggest', 'summar', 'summari', 'summer', 'sun', 'sunday', 'sunglass', 'super', 'suppos', 'sure', 'surpris', 'sushi', 'sweet', 'swung', 'tabl', 'taco', 'tailor', 'take', 'takeout', 'talk', 'tap', 'tapa', 'tartar', 'tast', 'tasteless', 'tasti', 'tater', 'tea', 'teamwork', 'teeth', 'tell', 'temp', 'ten', 'tender', 'tepid', 'terribl', 'terrif', 'textur', 'th', 'thai', 'thank', 'that', 'theft', 'thick', 'thin', 'thing', 'think', 'thinli', 'third', 'thirti', 'thoroughli', 'though', 'thought', 'three', 'thrill', 'thru', 'thu', 'thumb', 'tigerlilli', 'time', 'tini', 'tip', 'tiramisu', 'toast', 'today', 'togeth', 'told', 'toler', 'tomato', 'tongu', 'tonight', 'took', 'top', 'topic', 'toro', 'tot', 'total', 'touch', 'tough', 'toward', 'town', 'track', 'tradit', 'tragedi', 'transcend', 'trap', 'treat', 'tri', 'tribut', 'trim', 'trip', 'trippi', 'truffl', 'truli', 'tucson', 'tummi', 'tuna', 'turkey', 'turn', 'tv', 'twice', 'two', 'typic', 'unbeliev', 'undercook', 'understand', 'underwhelm', 'unexperienc', 'unfortun', 'unhealthi', 'uninspir', 'uniqu', 'unless', 'unprofession', 'unreal', 'unsatisfi', 'untoast', 'unwelcom', 'unwrap', 'updat', 'upgrad', 'upload', 'us', 'use', 'usual', 'vacant', 'vain', 'valley', 'valu', 'vanilla', 'veal', 'vega', 'vegan', 'veget', 'vegetarian', 'veggi', 'veggitarian', 'velvet', 'ventil', 'ventur', 'venu', 'verg', 'version', 'via', 'vibe', 'vinaigrett', 'vinegrett', 'violinist', 'visit', 'vodka', 'vomit', 'voodoo', 'vote', 'waaaaaayyyyyyyyyi', 'wagyu', 'wait', 'waiter', 'waitress', 'walk', 'wall', 'want', 'warm', 'warmer', 'warn', 'wash', 'wast', 'watch', 'water', 'wave', 'way', 'wayyy', 'weak', 'websit', 'wedg', 'week', 'weekend', 'weekli', 'weird', 'welcom', 'well', 'went', 'whatsoev', 'whelm', 'whenev', 'whether', 'white', 'whole', 'wide', 'wienerschnitzel', 'wife', 'wildli', 'wine', 'wing', 'winner', 'wire', 'wish', 'wit', 'without', 'wonder', 'wonton', 'word', 'work', 'worker', 'world', 'worri', 'wors', 'worst', 'worth', 'would', 'wound', 'wow', 'wrap', 'write', 'wrong', 'ya', 'yama', 'yay', 'yeah', 'year', 'yellow', 'yellowtail', 'yelper', 'yet', 'yucki', 'yukon', 'yum', 'yummi', 'zero']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ink4_Pda-LS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uuu_IiwubQFq"
      },
      "source": [
        "sentiments = []\n",
        "sentiments.append(\"this restaurant sucks, really bad\")\n",
        "sentiments.append(\"great place great food\")\n",
        "sentiments.append(\"food tasted good. I will visit again\")\n",
        "sentiments.append(\"just horrible. I will never set foot again\")\n",
        "sentiments.append(\"My wife finds the food very good.\")\n",
        "sentiments.append(\"Just two words: unpleasant and dirty.\")\n",
        "sentiments.append(\"Clean, friendly, good food\")\n",
        "\n",
        "vectorized_sentiments = cv.transform(sentiments).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHQliURSoNPW"
      },
      "source": [
        "y_pred = classifier.predict(vectorized_sentiments)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1J9rpXi9ovPF",
        "outputId": "b294d5f4-52e5-4980-cbb2-7c184550e526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 1 0 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhjdrKNyZanY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}